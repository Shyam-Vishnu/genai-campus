window.GENAI_COURSE = [{"id": "foundations.intro", "title": "What is Generative AI?", "time": "7 min", "video": [{"url": "https://www.youtube.com/watch?v=zjkBMFhNj_g", "start": 0, "title": "Intro to LLMs (Karpathy)"}, {"url": "https://www.youtube.com/watch?v=aircAruvnKk", "start": 0, "title": "Neural nets visual (3B1B)"}], "content": "<h3>What is Generative AI?</h3><p>GenAI creates <em>new</em> content by learning patterns; outputs include text, code, images, audio.</p>", "questions": [{"type": "mcq", "prompt": "Which is NOT a typical GenAI output?", "options": ["Text", "Images", "Network packets", "Code"], "answerIndex": 2}]}, {"id": "foundations.history", "title": "Brief History of GenAI", "time": "8 min", "video": [{"url": "https://www.youtube.com/watch?v=VwVg9jCtqaU", "start": 0, "title": "From RNNs to Transformers (overview)"}], "content": "<h3>From n‑grams → RNNs/LSTM → Transformers</h3><p>Scaling and attention drove the step change in capability.</p>", "questions": [{"type": "text", "prompt": "One RNN limitation Transformers fixed.", "rubric": ["parallel", "long", "vanishing", "context"]}]}, {"id": "llms.tokens", "title": "Tokens & Embeddings", "time": "9 min", "video": [{"url": "https://www.youtube.com/watch?v=8cAffg2jaT0", "start": 0, "title": "Embeddings intuition (StatQuest)"}], "content": "<h3>Tokens & Embeddings</h3><p>Subword tokens → vectors; distance approximates semantic similarity.</p>", "questions": [{"type": "mcq", "prompt": "What is an embedding?", "options": ["Compressed image", "Vector of meaning", "Tokenizer bug", "Hyperparameter"], "answerIndex": 1}]}, {"id": "llms.attention", "title": "Attention & Transformers", "time": "12 min", "video": [{"url": "https://www.youtube.com/watch?v=eMlx5fFNoYc", "start": 0, "title": "Visualizing Transformers (3B1B)"}, {"url": "https://www.youtube.com/watch?v=U0s0f995w14", "start": 0, "title": "Attention explained (talk)"}], "content": "<h3>Self‑Attention</h3><p>Queries, Keys, Values produce weighted context; stacked with MLP + residuals.</p>", "questions": [{"type": "mcq", "prompt": "Why did Transformers replace many RNNs?", "options": ["Ignore context", "Parallel + long‑range", "Always smaller", "Only for vision"], "answerIndex": 1}]}, {"id": "llms.decoding", "title": "Sampling & Decoding", "time": "8 min", "video": [{"url": "https://www.youtube.com/watch?v=3b0Twcjb1x8", "start": 0, "title": "Temperature/top‑k/top‑p"}], "content": "<h3>Decoding</h3><p>Control determinism vs creativity via temperature, top‑k, top‑p.</p>", "questions": [{"type": "mcq", "prompt": "Raising temperature makes outputs…", "options": ["More deterministic", "More diverse", "Shorter", "Always better"], "answerIndex": 1}]}, {"id": "llms.context", "title": "Context Windows & Memory", "time": "7 min", "video": [{"url": "https://www.youtube.com/watch?v=kCc8FmEb1nY", "start": 0, "title": "Let's build GPT (Karpathy deep dive)"}], "content": "<h3>Context</h3><p>Token limits constrain inputs — use summarization, retrieval, and tools.</p>", "questions": [{"type": "text", "prompt": "One tactic to fit long docs into small contexts.", "rubric": ["summarize", "chunk", "retrieve", "rag", "map-reduce"]}]}, {"id": "prompting.core", "title": "Prompt Engineering", "time": "10 min", "video": [{"url": "https://www.youtube.com/watch?v=D8qGQe6eXU8", "start": 0, "title": "Prompting fundamentals"}], "content": "<h3>Prompt patterns</h3><ul><li>Role, task, constraints</li><li>Examples</li><li>Output schema</li></ul>", "questions": [{"type": "text", "prompt": "Write one constraint for a summary.", "rubric": ["word", "limit", "bullets", "tone", "audience", "format"]}, {"type": "mcq", "prompt": "What reduces randomness?", "options": ["Longer context", "Clear constraints", "No examples", "Ambiguous goals"], "answerIndex": 1}]}, {"id": "prompting.advanced", "title": "Advanced Prompting (Plans, Roles, Self‑Checks)", "time": "12 min", "video": [{"url": "https://www.youtube.com/watch?v=8uqXuEZLyUU", "start": 0, "title": "Advanced prompting (concise)"}], "content": "<h3>Scaffolding</h3><p>Decompose tasks, require self‑checks, add rubrics & tests.</p>", "questions": [{"type": "mcq", "prompt": "Which trims overly long outputs?", "options": ["Higher temp", "No constraints", "Explicit word limit", "Vaguer prompt"], "answerIndex": 2}]}, {"id": "rag.basics", "title": "RAG Basics", "time": "10 min", "video": [{"url": "https://www.youtube.com/watch?v=U1cFh-5C0lU", "start": 0, "title": "What is RAG?"}], "content": "<h3>RAG steps</h3><ol><li>Chunk & embed</li><li>Retrieve top‑k</li><li>Grounded prompt</li><li>Generate with citations</li></ol>", "questions": [{"type": "mcq", "prompt": "First step in RAG?", "options": ["Generate", "Chunk & embed", "Evaluate", "Deploy"], "answerIndex": 1}]}, {"id": "rag.quality", "title": "RAG Quality & Evaluation", "time": "9 min", "video": [{"url": "https://www.youtube.com/watch?v=7M8X6A3ZBfY", "start": 0, "title": "Improving retrieval quality"}], "content": "<h3>Quality levers</h3><p>Chunk size, hybrid search, rerankers, query rewrite.</p>", "questions": [{"type": "text", "prompt": "One metric for grounded answers.", "rubric": ["faithful", "citation", "coverage", "latency", "precision", "recall"]}]}, {"id": "rag.guardrails", "title": "Guardrails for RAG", "time": "8 min", "video": [{"url": "https://www.youtube.com/watch?v=Y6R8JvG0Q2Q", "start": 0, "title": "Prompt injection defenses"}], "content": "<h3>Defenses</h3><p>Sanitize inputs, isolate tools, restrict domains, cite sources, verify.</p>", "questions": [{"type": "text", "prompt": "One defense against prompt injection.", "rubric": ["sanitize", "isolation", "escape", "policy", "filter"]}]}, {"id": "finetune.overview", "title": "Fine‑Tuning Overview", "time": "9 min", "video": [{"url": "https://www.youtube.com/watch?v=9-Jl0dxG8wQ", "start": 0, "title": "When to fine‑tune vs RAG"}], "content": "<h3>When FT helps</h3><p>Style adherence, structured outputs, domain jargon; use RAG for volatile facts.</p>", "questions": [{"type": "mcq", "prompt": "Pick the better choice for rapidly changing facts.", "options": ["Fine‑tune", "RAG"], "answerIndex": 1}]}, {"id": "finetune.adapters", "title": "Adapters (LoRA/PEFT)", "time": "10 min", "video": [{"url": "https://www.youtube.com/watch?v=8Oog7TXHvFY", "start": 0, "title": "LoRA explained"}], "content": "<h3>Adapters</h3><p>Train small low‑rank weights; cheaper & less overfit.</p>", "questions": [{"type": "mcq", "prompt": "Adapters primarily…", "options": ["Retrain full model", "Update low‑rank weights", "Change tokenizer", "Extend context"], "answerIndex": 1}]}, {"id": "finetune.data", "title": "Data & Evaluation for FT", "time": "9 min", "video": [{"url": "https://www.youtube.com/watch?v=5qJ_0GiR4wA", "start": 0, "title": "Dataset curation pitfalls"}], "content": "<h3>Data</h3><p>High‑quality pairs; balanced classes; holdout tests; measure style & exactness.</p>", "questions": [{"type": "text", "prompt": "One pitfall when curating FT data.", "rubric": ["leakage", "bias", "imbalance", "duplicates", "overfit"]}]}, {"id": "safety.ethics", "title": "Safety & Governance", "time": "8 min", "video": [{"url": "https://www.youtube.com/watch?v=otb6_6FQK8U", "start": 0, "title": "Responsible AI overview"}], "content": "<h3>Safety</h3><p>Mitigate toxicity, privacy leaks, jailbreaks; rate limits; user education.</p>", "questions": [{"type": "mcq", "prompt": "Which protects user data best?", "options": ["Log secrets", "Encrypt & minimize logs", "Share API keys", "Open CORS"], "answerIndex": 1}]}, {"id": "eval.metrics", "title": "Evaluation & Observability", "time": "9 min", "video": [{"url": "https://www.youtube.com/watch?v=PLyqO-r3uQw", "start": 0, "title": "Measuring model performance"}], "content": "<h3>Observe</h3><p>Track latency, cost, error rate, qualitative ratings; A/B test.</p>", "questions": [{"type": "mcq", "prompt": "Not an observability signal?", "options": ["Latency", "Token usage", "Cost", "User's SSN"], "answerIndex": 3}]}, {"id": "agents.tools", "title": "Tools & Function Calling", "time": "10 min", "video": [{"url": "https://www.youtube.com/watch?v=FQJ3B1xH9Wc", "start": 0, "title": "Tool/function calling intro"}], "content": "<h3>Tool use</h3><p>Define schemas; validate; timeouts & retries; sandbox side effects.</p>", "questions": [{"type": "text", "prompt": "One safeguard for tools.", "rubric": ["schema", "validate", "timeout", "rate", "approval", "sandbox"]}]}, {"id": "agents.planning", "title": "Agents & Planning", "time": "11 min", "video": [{"url": "https://www.youtube.com/watch?v=3Q2d1N6sG4s", "start": 0, "title": "Agents, planning & tools"}], "content": "<h3>Agents</h3><p>Plan → act → observe → iterate. Guard against loops/tool abuse.</p>", "questions": [{"type": "mcq", "prompt": "Agents should include…", "options": ["Infinite retries", "Human‑in‑the‑loop for risky steps", "No validation", "No logs"], "answerIndex": 1}]}, {"id": "deploy.multimodal", "title": "Multimodal Models", "time": "10 min", "video": [{"url": "https://www.youtube.com/watch?v=szL2eV2UUDg", "start": 0, "title": "What are multimodal models?"}], "content": "<h3>Multimodal</h3><p>Combine modalities for stronger grounding and UX.</p>", "questions": [{"type": "text", "prompt": "One benefit of on‑device multimodal.", "rubric": ["latency", "privacy", "offline", "accessibility"]}]}, {"id": "deploy.ops", "title": "Deployment & Ops", "time": "10 min", "video": [{"url": "https://www.youtube.com/watch?v=A3l6SxB7c5k", "start": 0, "title": "Operating LLM apps"}], "content": "<h3>Ops</h3><p>Keys management, quotas, caching, fallback models, canary releases, SLOs.</p>", "questions": [{"type": "mcq", "prompt": "What controls cost at scale?", "options": ["Disable caching", "Unlimited retries", "Response caching & smaller models", "No limits"], "answerIndex": 2}]}, {"id": "deploy.costs", "title": "Cost, Latency & Caching", "time": "8 min", "video": [{"url": "https://www.youtube.com/watch?v=QfV9AkHkLhM", "start": 0, "title": "Optimize latency & cost"}], "content": "<h3>Optimize</h3><p>Cache templates, batch requests, right‑size models, local pre/post‑processing.</p>", "questions": [{"type": "text", "prompt": "One safe caching target.", "rubric": ["static", "template", "non‑personalized", "public"]}]}, {"id": "capstone.project", "title": "Capstone: Build a Mini RAG App", "time": "25 min", "video": [{"url": "https://www.youtube.com/watch?v=BrsocJb-fAo", "start": 0, "title": "RAG from scratch (walk‑through)"}], "content": "<h3>Capstone</h3><ol><li>Choose docs</li><li>Chunk & embed</li><li>Top‑k retrieval</li><li>Grounded answer + citations</li><li>Evaluate faithfulness</li></ol>", "questions": [{"type": "text", "prompt": "Paste a link to your demo or repo.", "rubric": ["http", "https", "github", "pages", "vercel", "netlify"]}]}];
window.GENAI_PROJECTS = [{"id": "proj.promptlib", "title": "Design a Prompt Library", "description": "Curate 10 reusable prompts with roles, constraints, and output schemas.", "reward": "Bronze Badge"}, {"id": "proj.ragdemo", "title": "Build a Tiny RAG Notebook", "description": "Chunk→embed→retrieve→answer with citations.", "reward": "Silver Badge"}, {"id": "proj.safetycheck", "title": "Write Safety Checks", "description": "Define 10 red‑flag cases and app responses.", "reward": "Gold Badge"}];
